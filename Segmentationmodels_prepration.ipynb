{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-ss/Semantic-Segmentation-COVID-19/blob/main/Segmentationmodels_prepration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA5UmJzgyrYz",
        "outputId": "b743e8d2-5520-4288-e004-9d87d211822c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-o4CQ7poZ-X"
      },
      "source": [
        "import numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toQq6ZfJy7RV",
        "outputId": "d4455314-f109-4a85-9997-9f53fb2d526b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7ZiSUqgzIkk",
        "outputId": "ee4a176f-70de-407f-e97c-5f18f756dc97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "img_input = keras.layers.Input(shape=(224, 224, 3)) # defining the Input shape\n",
        "Encoder_Dense = DenseNet121( weights = 'imagenet',include_top = False,input_tensor=img_input)\n",
        "model=Encoder_Dense\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 1s 0us/step\n",
            "Model: \"densenet121\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
            "                                                                 conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
            "                                                                 conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
            "                                                                 conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
            "                                                                 conv2_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
            "                                                                 conv2_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
            "                                                                 conv2_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
            "                                                                 conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
            "                                                                 conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
            "                                                                 conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
            "                                                                 conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
            "                                                                 conv3_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
            "                                                                 conv3_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
            "                                                                 conv3_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
            "                                                                 conv3_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
            "                                                                 conv3_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
            "                                                                 conv3_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
            "                                                                 conv3_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
            "                                                                 conv3_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
            "                                                                 conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
            "                                                                 conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
            "                                                                 conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
            "                                                                 conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
            "                                                                 conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
            "                                                                 conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
            "                                                                 conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
            "                                                                 conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
            "                                                                 conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
            "                                                                 conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
            "                                                                 conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
            "                                                                 conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
            "                                                                 conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
            "                                                                 conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
            "                                                                 conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
            "                                                                 conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
            "                                                                 conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
            "                                                                 conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
            "                                                                 conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
            "                                                                 conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
            "                                                                 conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
            "                                                                 conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
            "                                                                 conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
            "                                                                 conv4_block24_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_bn (BatchNormalization)   (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_relu (Activation)         (None, 14, 14, 1024) 0           pool4_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool4_conv (Conv2D)             (None, 14, 14, 512)  524288      pool4_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool4_pool (AveragePooling2D)   (None, 7, 7, 512)    0           pool4_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 512)    2048        pool4_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_relu (Activation (None, 7, 7, 512)    0           conv5_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    65536       conv5_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_concat (Concatenat (None, 7, 7, 544)    0           pool4_pool[0][0]                 \n",
            "                                                                 conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_bn (BatchNormali (None, 7, 7, 544)    2176        conv5_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_relu (Activation (None, 7, 7, 544)    0           conv5_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    69632       conv5_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_concat (Concatenat (None, 7, 7, 576)    0           conv5_block1_concat[0][0]        \n",
            "                                                                 conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_bn (BatchNormali (None, 7, 7, 576)    2304        conv5_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_relu (Activation (None, 7, 7, 576)    0           conv5_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    73728       conv5_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_concat (Concatenat (None, 7, 7, 608)    0           conv5_block2_concat[0][0]        \n",
            "                                                                 conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_bn (BatchNormali (None, 7, 7, 608)    2432        conv5_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_relu (Activation (None, 7, 7, 608)    0           conv5_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    77824       conv5_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_concat (Concatenat (None, 7, 7, 640)    0           conv5_block3_concat[0][0]        \n",
            "                                                                 conv5_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_bn (BatchNormali (None, 7, 7, 640)    2560        conv5_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_relu (Activation (None, 7, 7, 640)    0           conv5_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_concat (Concatenat (None, 7, 7, 672)    0           conv5_block4_concat[0][0]        \n",
            "                                                                 conv5_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_relu (Activation (None, 7, 7, 672)    0           conv5_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_concat (Concatenat (None, 7, 7, 704)    0           conv5_block5_concat[0][0]        \n",
            "                                                                 conv5_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_relu (Activation (None, 7, 7, 704)    0           conv5_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_concat (Concatenat (None, 7, 7, 736)    0           conv5_block6_concat[0][0]        \n",
            "                                                                 conv5_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_relu (Activation (None, 7, 7, 736)    0           conv5_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_concat (Concatenat (None, 7, 7, 768)    0           conv5_block7_concat[0][0]        \n",
            "                                                                 conv5_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_relu (Activation (None, 7, 7, 768)    0           conv5_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_concat (Concatenat (None, 7, 7, 800)    0           conv5_block8_concat[0][0]        \n",
            "                                                                 conv5_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_bn (BatchNormal (None, 7, 7, 800)    3200        conv5_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_relu (Activatio (None, 7, 7, 800)    0           conv5_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    102400      conv5_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_concat (Concatena (None, 7, 7, 832)    0           conv5_block9_concat[0][0]        \n",
            "                                                                 conv5_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_bn (BatchNormal (None, 7, 7, 832)    3328        conv5_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_relu (Activatio (None, 7, 7, 832)    0           conv5_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    106496      conv5_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_concat (Concatena (None, 7, 7, 864)    0           conv5_block10_concat[0][0]       \n",
            "                                                                 conv5_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_bn (BatchNormal (None, 7, 7, 864)    3456        conv5_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_relu (Activatio (None, 7, 7, 864)    0           conv5_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    110592      conv5_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_concat (Concatena (None, 7, 7, 896)    0           conv5_block11_concat[0][0]       \n",
            "                                                                 conv5_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_bn (BatchNormal (None, 7, 7, 896)    3584        conv5_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_relu (Activatio (None, 7, 7, 896)    0           conv5_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    114688      conv5_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_concat (Concatena (None, 7, 7, 928)    0           conv5_block12_concat[0][0]       \n",
            "                                                                 conv5_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_concat (Concatena (None, 7, 7, 960)    0           conv5_block13_concat[0][0]       \n",
            "                                                                 conv5_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_concat (Concatena (None, 7, 7, 992)    0           conv5_block14_concat[0][0]       \n",
            "                                                                 conv5_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_concat (Concatena (None, 7, 7, 1024)   0           conv5_block15_concat[0][0]       \n",
            "                                                                 conv5_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "bn (BatchNormalization)         (None, 7, 7, 1024)   4096        conv5_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "relu (Activation)               (None, 7, 7, 1024)   0           bn[0][0]                         \n",
            "==================================================================================================\n",
            "Total params: 7,037,504\n",
            "Trainable params: 6,953,856\n",
            "Non-trainable params: 83,648\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHEJ-Qj3zIn0",
        "outputId": "d11e1c2a-c354-4a25-dee4-023d1c50c1ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Encoder = keras.layers.SeparableConv2D(filters = 1024,kernel_size = (3, 3),activation = 'relu',kernel_initializer='he_normal',padding=\"same\")(Encoder_Dense.output)\n",
        "Encoder = keras.layers.BatchNormalization()(Encoder)\n",
        "print(Encoder.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 7, 7, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjxZ1etxzZy8",
        "outputId": "bc88755d-9da7-415a-b3cb-3237644ea8a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i, layer in enumerate(model.layers):\n",
        "   print(i, layer.name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_1\n",
            "1 zero_padding2d\n",
            "2 conv1/conv\n",
            "3 conv1/bn\n",
            "4 conv1/relu\n",
            "5 zero_padding2d_1\n",
            "6 pool1\n",
            "7 conv2_block1_0_bn\n",
            "8 conv2_block1_0_relu\n",
            "9 conv2_block1_1_conv\n",
            "10 conv2_block1_1_bn\n",
            "11 conv2_block1_1_relu\n",
            "12 conv2_block1_2_conv\n",
            "13 conv2_block1_concat\n",
            "14 conv2_block2_0_bn\n",
            "15 conv2_block2_0_relu\n",
            "16 conv2_block2_1_conv\n",
            "17 conv2_block2_1_bn\n",
            "18 conv2_block2_1_relu\n",
            "19 conv2_block2_2_conv\n",
            "20 conv2_block2_concat\n",
            "21 conv2_block3_0_bn\n",
            "22 conv2_block3_0_relu\n",
            "23 conv2_block3_1_conv\n",
            "24 conv2_block3_1_bn\n",
            "25 conv2_block3_1_relu\n",
            "26 conv2_block3_2_conv\n",
            "27 conv2_block3_concat\n",
            "28 conv2_block4_0_bn\n",
            "29 conv2_block4_0_relu\n",
            "30 conv2_block4_1_conv\n",
            "31 conv2_block4_1_bn\n",
            "32 conv2_block4_1_relu\n",
            "33 conv2_block4_2_conv\n",
            "34 conv2_block4_concat\n",
            "35 conv2_block5_0_bn\n",
            "36 conv2_block5_0_relu\n",
            "37 conv2_block5_1_conv\n",
            "38 conv2_block5_1_bn\n",
            "39 conv2_block5_1_relu\n",
            "40 conv2_block5_2_conv\n",
            "41 conv2_block5_concat\n",
            "42 conv2_block6_0_bn\n",
            "43 conv2_block6_0_relu\n",
            "44 conv2_block6_1_conv\n",
            "45 conv2_block6_1_bn\n",
            "46 conv2_block6_1_relu\n",
            "47 conv2_block6_2_conv\n",
            "48 conv2_block6_concat\n",
            "49 pool2_bn\n",
            "50 pool2_relu\n",
            "51 pool2_conv\n",
            "52 pool2_pool\n",
            "53 conv3_block1_0_bn\n",
            "54 conv3_block1_0_relu\n",
            "55 conv3_block1_1_conv\n",
            "56 conv3_block1_1_bn\n",
            "57 conv3_block1_1_relu\n",
            "58 conv3_block1_2_conv\n",
            "59 conv3_block1_concat\n",
            "60 conv3_block2_0_bn\n",
            "61 conv3_block2_0_relu\n",
            "62 conv3_block2_1_conv\n",
            "63 conv3_block2_1_bn\n",
            "64 conv3_block2_1_relu\n",
            "65 conv3_block2_2_conv\n",
            "66 conv3_block2_concat\n",
            "67 conv3_block3_0_bn\n",
            "68 conv3_block3_0_relu\n",
            "69 conv3_block3_1_conv\n",
            "70 conv3_block3_1_bn\n",
            "71 conv3_block3_1_relu\n",
            "72 conv3_block3_2_conv\n",
            "73 conv3_block3_concat\n",
            "74 conv3_block4_0_bn\n",
            "75 conv3_block4_0_relu\n",
            "76 conv3_block4_1_conv\n",
            "77 conv3_block4_1_bn\n",
            "78 conv3_block4_1_relu\n",
            "79 conv3_block4_2_conv\n",
            "80 conv3_block4_concat\n",
            "81 conv3_block5_0_bn\n",
            "82 conv3_block5_0_relu\n",
            "83 conv3_block5_1_conv\n",
            "84 conv3_block5_1_bn\n",
            "85 conv3_block5_1_relu\n",
            "86 conv3_block5_2_conv\n",
            "87 conv3_block5_concat\n",
            "88 conv3_block6_0_bn\n",
            "89 conv3_block6_0_relu\n",
            "90 conv3_block6_1_conv\n",
            "91 conv3_block6_1_bn\n",
            "92 conv3_block6_1_relu\n",
            "93 conv3_block6_2_conv\n",
            "94 conv3_block6_concat\n",
            "95 conv3_block7_0_bn\n",
            "96 conv3_block7_0_relu\n",
            "97 conv3_block7_1_conv\n",
            "98 conv3_block7_1_bn\n",
            "99 conv3_block7_1_relu\n",
            "100 conv3_block7_2_conv\n",
            "101 conv3_block7_concat\n",
            "102 conv3_block8_0_bn\n",
            "103 conv3_block8_0_relu\n",
            "104 conv3_block8_1_conv\n",
            "105 conv3_block8_1_bn\n",
            "106 conv3_block8_1_relu\n",
            "107 conv3_block8_2_conv\n",
            "108 conv3_block8_concat\n",
            "109 conv3_block9_0_bn\n",
            "110 conv3_block9_0_relu\n",
            "111 conv3_block9_1_conv\n",
            "112 conv3_block9_1_bn\n",
            "113 conv3_block9_1_relu\n",
            "114 conv3_block9_2_conv\n",
            "115 conv3_block9_concat\n",
            "116 conv3_block10_0_bn\n",
            "117 conv3_block10_0_relu\n",
            "118 conv3_block10_1_conv\n",
            "119 conv3_block10_1_bn\n",
            "120 conv3_block10_1_relu\n",
            "121 conv3_block10_2_conv\n",
            "122 conv3_block10_concat\n",
            "123 conv3_block11_0_bn\n",
            "124 conv3_block11_0_relu\n",
            "125 conv3_block11_1_conv\n",
            "126 conv3_block11_1_bn\n",
            "127 conv3_block11_1_relu\n",
            "128 conv3_block11_2_conv\n",
            "129 conv3_block11_concat\n",
            "130 conv3_block12_0_bn\n",
            "131 conv3_block12_0_relu\n",
            "132 conv3_block12_1_conv\n",
            "133 conv3_block12_1_bn\n",
            "134 conv3_block12_1_relu\n",
            "135 conv3_block12_2_conv\n",
            "136 conv3_block12_concat\n",
            "137 pool3_bn\n",
            "138 pool3_relu\n",
            "139 pool3_conv\n",
            "140 pool3_pool\n",
            "141 conv4_block1_0_bn\n",
            "142 conv4_block1_0_relu\n",
            "143 conv4_block1_1_conv\n",
            "144 conv4_block1_1_bn\n",
            "145 conv4_block1_1_relu\n",
            "146 conv4_block1_2_conv\n",
            "147 conv4_block1_concat\n",
            "148 conv4_block2_0_bn\n",
            "149 conv4_block2_0_relu\n",
            "150 conv4_block2_1_conv\n",
            "151 conv4_block2_1_bn\n",
            "152 conv4_block2_1_relu\n",
            "153 conv4_block2_2_conv\n",
            "154 conv4_block2_concat\n",
            "155 conv4_block3_0_bn\n",
            "156 conv4_block3_0_relu\n",
            "157 conv4_block3_1_conv\n",
            "158 conv4_block3_1_bn\n",
            "159 conv4_block3_1_relu\n",
            "160 conv4_block3_2_conv\n",
            "161 conv4_block3_concat\n",
            "162 conv4_block4_0_bn\n",
            "163 conv4_block4_0_relu\n",
            "164 conv4_block4_1_conv\n",
            "165 conv4_block4_1_bn\n",
            "166 conv4_block4_1_relu\n",
            "167 conv4_block4_2_conv\n",
            "168 conv4_block4_concat\n",
            "169 conv4_block5_0_bn\n",
            "170 conv4_block5_0_relu\n",
            "171 conv4_block5_1_conv\n",
            "172 conv4_block5_1_bn\n",
            "173 conv4_block5_1_relu\n",
            "174 conv4_block5_2_conv\n",
            "175 conv4_block5_concat\n",
            "176 conv4_block6_0_bn\n",
            "177 conv4_block6_0_relu\n",
            "178 conv4_block6_1_conv\n",
            "179 conv4_block6_1_bn\n",
            "180 conv4_block6_1_relu\n",
            "181 conv4_block6_2_conv\n",
            "182 conv4_block6_concat\n",
            "183 conv4_block7_0_bn\n",
            "184 conv4_block7_0_relu\n",
            "185 conv4_block7_1_conv\n",
            "186 conv4_block7_1_bn\n",
            "187 conv4_block7_1_relu\n",
            "188 conv4_block7_2_conv\n",
            "189 conv4_block7_concat\n",
            "190 conv4_block8_0_bn\n",
            "191 conv4_block8_0_relu\n",
            "192 conv4_block8_1_conv\n",
            "193 conv4_block8_1_bn\n",
            "194 conv4_block8_1_relu\n",
            "195 conv4_block8_2_conv\n",
            "196 conv4_block8_concat\n",
            "197 conv4_block9_0_bn\n",
            "198 conv4_block9_0_relu\n",
            "199 conv4_block9_1_conv\n",
            "200 conv4_block9_1_bn\n",
            "201 conv4_block9_1_relu\n",
            "202 conv4_block9_2_conv\n",
            "203 conv4_block9_concat\n",
            "204 conv4_block10_0_bn\n",
            "205 conv4_block10_0_relu\n",
            "206 conv4_block10_1_conv\n",
            "207 conv4_block10_1_bn\n",
            "208 conv4_block10_1_relu\n",
            "209 conv4_block10_2_conv\n",
            "210 conv4_block10_concat\n",
            "211 conv4_block11_0_bn\n",
            "212 conv4_block11_0_relu\n",
            "213 conv4_block11_1_conv\n",
            "214 conv4_block11_1_bn\n",
            "215 conv4_block11_1_relu\n",
            "216 conv4_block11_2_conv\n",
            "217 conv4_block11_concat\n",
            "218 conv4_block12_0_bn\n",
            "219 conv4_block12_0_relu\n",
            "220 conv4_block12_1_conv\n",
            "221 conv4_block12_1_bn\n",
            "222 conv4_block12_1_relu\n",
            "223 conv4_block12_2_conv\n",
            "224 conv4_block12_concat\n",
            "225 conv4_block13_0_bn\n",
            "226 conv4_block13_0_relu\n",
            "227 conv4_block13_1_conv\n",
            "228 conv4_block13_1_bn\n",
            "229 conv4_block13_1_relu\n",
            "230 conv4_block13_2_conv\n",
            "231 conv4_block13_concat\n",
            "232 conv4_block14_0_bn\n",
            "233 conv4_block14_0_relu\n",
            "234 conv4_block14_1_conv\n",
            "235 conv4_block14_1_bn\n",
            "236 conv4_block14_1_relu\n",
            "237 conv4_block14_2_conv\n",
            "238 conv4_block14_concat\n",
            "239 conv4_block15_0_bn\n",
            "240 conv4_block15_0_relu\n",
            "241 conv4_block15_1_conv\n",
            "242 conv4_block15_1_bn\n",
            "243 conv4_block15_1_relu\n",
            "244 conv4_block15_2_conv\n",
            "245 conv4_block15_concat\n",
            "246 conv4_block16_0_bn\n",
            "247 conv4_block16_0_relu\n",
            "248 conv4_block16_1_conv\n",
            "249 conv4_block16_1_bn\n",
            "250 conv4_block16_1_relu\n",
            "251 conv4_block16_2_conv\n",
            "252 conv4_block16_concat\n",
            "253 conv4_block17_0_bn\n",
            "254 conv4_block17_0_relu\n",
            "255 conv4_block17_1_conv\n",
            "256 conv4_block17_1_bn\n",
            "257 conv4_block17_1_relu\n",
            "258 conv4_block17_2_conv\n",
            "259 conv4_block17_concat\n",
            "260 conv4_block18_0_bn\n",
            "261 conv4_block18_0_relu\n",
            "262 conv4_block18_1_conv\n",
            "263 conv4_block18_1_bn\n",
            "264 conv4_block18_1_relu\n",
            "265 conv4_block18_2_conv\n",
            "266 conv4_block18_concat\n",
            "267 conv4_block19_0_bn\n",
            "268 conv4_block19_0_relu\n",
            "269 conv4_block19_1_conv\n",
            "270 conv4_block19_1_bn\n",
            "271 conv4_block19_1_relu\n",
            "272 conv4_block19_2_conv\n",
            "273 conv4_block19_concat\n",
            "274 conv4_block20_0_bn\n",
            "275 conv4_block20_0_relu\n",
            "276 conv4_block20_1_conv\n",
            "277 conv4_block20_1_bn\n",
            "278 conv4_block20_1_relu\n",
            "279 conv4_block20_2_conv\n",
            "280 conv4_block20_concat\n",
            "281 conv4_block21_0_bn\n",
            "282 conv4_block21_0_relu\n",
            "283 conv4_block21_1_conv\n",
            "284 conv4_block21_1_bn\n",
            "285 conv4_block21_1_relu\n",
            "286 conv4_block21_2_conv\n",
            "287 conv4_block21_concat\n",
            "288 conv4_block22_0_bn\n",
            "289 conv4_block22_0_relu\n",
            "290 conv4_block22_1_conv\n",
            "291 conv4_block22_1_bn\n",
            "292 conv4_block22_1_relu\n",
            "293 conv4_block22_2_conv\n",
            "294 conv4_block22_concat\n",
            "295 conv4_block23_0_bn\n",
            "296 conv4_block23_0_relu\n",
            "297 conv4_block23_1_conv\n",
            "298 conv4_block23_1_bn\n",
            "299 conv4_block23_1_relu\n",
            "300 conv4_block23_2_conv\n",
            "301 conv4_block23_concat\n",
            "302 conv4_block24_0_bn\n",
            "303 conv4_block24_0_relu\n",
            "304 conv4_block24_1_conv\n",
            "305 conv4_block24_1_bn\n",
            "306 conv4_block24_1_relu\n",
            "307 conv4_block24_2_conv\n",
            "308 conv4_block24_concat\n",
            "309 pool4_bn\n",
            "310 pool4_relu\n",
            "311 pool4_conv\n",
            "312 pool4_pool\n",
            "313 conv5_block1_0_bn\n",
            "314 conv5_block1_0_relu\n",
            "315 conv5_block1_1_conv\n",
            "316 conv5_block1_1_bn\n",
            "317 conv5_block1_1_relu\n",
            "318 conv5_block1_2_conv\n",
            "319 conv5_block1_concat\n",
            "320 conv5_block2_0_bn\n",
            "321 conv5_block2_0_relu\n",
            "322 conv5_block2_1_conv\n",
            "323 conv5_block2_1_bn\n",
            "324 conv5_block2_1_relu\n",
            "325 conv5_block2_2_conv\n",
            "326 conv5_block2_concat\n",
            "327 conv5_block3_0_bn\n",
            "328 conv5_block3_0_relu\n",
            "329 conv5_block3_1_conv\n",
            "330 conv5_block3_1_bn\n",
            "331 conv5_block3_1_relu\n",
            "332 conv5_block3_2_conv\n",
            "333 conv5_block3_concat\n",
            "334 conv5_block4_0_bn\n",
            "335 conv5_block4_0_relu\n",
            "336 conv5_block4_1_conv\n",
            "337 conv5_block4_1_bn\n",
            "338 conv5_block4_1_relu\n",
            "339 conv5_block4_2_conv\n",
            "340 conv5_block4_concat\n",
            "341 conv5_block5_0_bn\n",
            "342 conv5_block5_0_relu\n",
            "343 conv5_block5_1_conv\n",
            "344 conv5_block5_1_bn\n",
            "345 conv5_block5_1_relu\n",
            "346 conv5_block5_2_conv\n",
            "347 conv5_block5_concat\n",
            "348 conv5_block6_0_bn\n",
            "349 conv5_block6_0_relu\n",
            "350 conv5_block6_1_conv\n",
            "351 conv5_block6_1_bn\n",
            "352 conv5_block6_1_relu\n",
            "353 conv5_block6_2_conv\n",
            "354 conv5_block6_concat\n",
            "355 conv5_block7_0_bn\n",
            "356 conv5_block7_0_relu\n",
            "357 conv5_block7_1_conv\n",
            "358 conv5_block7_1_bn\n",
            "359 conv5_block7_1_relu\n",
            "360 conv5_block7_2_conv\n",
            "361 conv5_block7_concat\n",
            "362 conv5_block8_0_bn\n",
            "363 conv5_block8_0_relu\n",
            "364 conv5_block8_1_conv\n",
            "365 conv5_block8_1_bn\n",
            "366 conv5_block8_1_relu\n",
            "367 conv5_block8_2_conv\n",
            "368 conv5_block8_concat\n",
            "369 conv5_block9_0_bn\n",
            "370 conv5_block9_0_relu\n",
            "371 conv5_block9_1_conv\n",
            "372 conv5_block9_1_bn\n",
            "373 conv5_block9_1_relu\n",
            "374 conv5_block9_2_conv\n",
            "375 conv5_block9_concat\n",
            "376 conv5_block10_0_bn\n",
            "377 conv5_block10_0_relu\n",
            "378 conv5_block10_1_conv\n",
            "379 conv5_block10_1_bn\n",
            "380 conv5_block10_1_relu\n",
            "381 conv5_block10_2_conv\n",
            "382 conv5_block10_concat\n",
            "383 conv5_block11_0_bn\n",
            "384 conv5_block11_0_relu\n",
            "385 conv5_block11_1_conv\n",
            "386 conv5_block11_1_bn\n",
            "387 conv5_block11_1_relu\n",
            "388 conv5_block11_2_conv\n",
            "389 conv5_block11_concat\n",
            "390 conv5_block12_0_bn\n",
            "391 conv5_block12_0_relu\n",
            "392 conv5_block12_1_conv\n",
            "393 conv5_block12_1_bn\n",
            "394 conv5_block12_1_relu\n",
            "395 conv5_block12_2_conv\n",
            "396 conv5_block12_concat\n",
            "397 conv5_block13_0_bn\n",
            "398 conv5_block13_0_relu\n",
            "399 conv5_block13_1_conv\n",
            "400 conv5_block13_1_bn\n",
            "401 conv5_block13_1_relu\n",
            "402 conv5_block13_2_conv\n",
            "403 conv5_block13_concat\n",
            "404 conv5_block14_0_bn\n",
            "405 conv5_block14_0_relu\n",
            "406 conv5_block14_1_conv\n",
            "407 conv5_block14_1_bn\n",
            "408 conv5_block14_1_relu\n",
            "409 conv5_block14_2_conv\n",
            "410 conv5_block14_concat\n",
            "411 conv5_block15_0_bn\n",
            "412 conv5_block15_0_relu\n",
            "413 conv5_block15_1_conv\n",
            "414 conv5_block15_1_bn\n",
            "415 conv5_block15_1_relu\n",
            "416 conv5_block15_2_conv\n",
            "417 conv5_block15_concat\n",
            "418 conv5_block16_0_bn\n",
            "419 conv5_block16_0_relu\n",
            "420 conv5_block16_1_conv\n",
            "421 conv5_block16_1_bn\n",
            "422 conv5_block16_1_relu\n",
            "423 conv5_block16_2_conv\n",
            "424 conv5_block16_concat\n",
            "425 bn\n",
            "426 relu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilnlSB2pzIqV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "de1a3dc4-4523-4f45-e112-6f71c640f666"
      },
      "source": [
        "Layer1=Encoder_Dense.get_layer(name=\"pool3_pool\").output\n",
        "print(Layer1.shape)\n",
        "Layer2=Encoder_Dense.get_layer(name=\"pool2_pool\").output\n",
        "print(Layer2.shape)\n",
        "Layer3=Encoder_Dense.get_layer(name=\"pool1\").output\n",
        "print(Layer3.shape)\n",
        "Layer4=Encoder_Dense.get_layer(name=\"conv1/bn\").output\n",
        "print(Layer4.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 14, 14, 256)\n",
            "(None, 28, 28, 128)\n",
            "(None, 56, 56, 64)\n",
            "(None, 112, 112, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBZ98E3Vz2wY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "999928cb-39a0-4cbe-be68-14100a1d6eb9"
      },
      "source": [
        "from tensorflow.keras.applications import Xception\n",
        "img_input = keras.layers.Input(shape=(224, 224, 3)) # defining the Input shape\n",
        "Encoder_Xception = Xception( weights = 'imagenet',include_top = False,input_tensor=img_input)\n",
        "model=Encoder_Xception\n",
        "#model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL0VXdtZz6ir",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "967a7484-5b08-4529-cb51-522a6073eaad"
      },
      "source": [
        "conv4 = Encoder_Xception.layers[121].output\n",
        "print(conv4)\n",
        "print(conv4.shape)\n",
        "conv3 = Encoder_Xception.layers[31].output\n",
        "print(conv3)\n",
        "print(conv3.shape)\n",
        "conv2 = Encoder_Xception.layers[21].output\n",
        "print(conv2)\n",
        "print(conv2.shape)\n",
        "conv1 = Encoder_Xception.layers[11].output\n",
        "print(conv1)\n",
        "print(conv1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"block13_sepconv2_bn/Identity:0\", shape=(None, 14, 14, 1024), dtype=float32)\n",
            "(None, 14, 14, 1024)\n",
            "Tensor(\"block4_sepconv2_bn/Identity:0\", shape=(None, 28, 28, 728), dtype=float32)\n",
            "(None, 28, 28, 728)\n",
            "Tensor(\"block3_sepconv2_bn/Identity:0\", shape=(None, 55, 55, 256), dtype=float32)\n",
            "(None, 55, 55, 256)\n",
            "Tensor(\"block2_sepconv2_bn/Identity:0\", shape=(None, 109, 109, 128), dtype=float32)\n",
            "(None, 109, 109, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97UWSOfuz-M8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6e84d132-d8f0-4b94-b405-92b5c679c64e"
      },
      "source": [
        "for i, layer in enumerate(Encoder_Xception.layers):\n",
        "   print(i, layer.name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_2\n",
            "1 block1_conv1\n",
            "2 block1_conv1_bn\n",
            "3 block1_conv1_act\n",
            "4 block1_conv2\n",
            "5 block1_conv2_bn\n",
            "6 block1_conv2_act\n",
            "7 block2_sepconv1\n",
            "8 block2_sepconv1_bn\n",
            "9 block2_sepconv2_act\n",
            "10 block2_sepconv2\n",
            "11 block2_sepconv2_bn\n",
            "12 conv2d\n",
            "13 block2_pool\n",
            "14 batch_normalization_1\n",
            "15 add\n",
            "16 block3_sepconv1_act\n",
            "17 block3_sepconv1\n",
            "18 block3_sepconv1_bn\n",
            "19 block3_sepconv2_act\n",
            "20 block3_sepconv2\n",
            "21 block3_sepconv2_bn\n",
            "22 conv2d_1\n",
            "23 block3_pool\n",
            "24 batch_normalization_2\n",
            "25 add_1\n",
            "26 block4_sepconv1_act\n",
            "27 block4_sepconv1\n",
            "28 block4_sepconv1_bn\n",
            "29 block4_sepconv2_act\n",
            "30 block4_sepconv2\n",
            "31 block4_sepconv2_bn\n",
            "32 conv2d_2\n",
            "33 block4_pool\n",
            "34 batch_normalization_3\n",
            "35 add_2\n",
            "36 block5_sepconv1_act\n",
            "37 block5_sepconv1\n",
            "38 block5_sepconv1_bn\n",
            "39 block5_sepconv2_act\n",
            "40 block5_sepconv2\n",
            "41 block5_sepconv2_bn\n",
            "42 block5_sepconv3_act\n",
            "43 block5_sepconv3\n",
            "44 block5_sepconv3_bn\n",
            "45 add_3\n",
            "46 block6_sepconv1_act\n",
            "47 block6_sepconv1\n",
            "48 block6_sepconv1_bn\n",
            "49 block6_sepconv2_act\n",
            "50 block6_sepconv2\n",
            "51 block6_sepconv2_bn\n",
            "52 block6_sepconv3_act\n",
            "53 block6_sepconv3\n",
            "54 block6_sepconv3_bn\n",
            "55 add_4\n",
            "56 block7_sepconv1_act\n",
            "57 block7_sepconv1\n",
            "58 block7_sepconv1_bn\n",
            "59 block7_sepconv2_act\n",
            "60 block7_sepconv2\n",
            "61 block7_sepconv2_bn\n",
            "62 block7_sepconv3_act\n",
            "63 block7_sepconv3\n",
            "64 block7_sepconv3_bn\n",
            "65 add_5\n",
            "66 block8_sepconv1_act\n",
            "67 block8_sepconv1\n",
            "68 block8_sepconv1_bn\n",
            "69 block8_sepconv2_act\n",
            "70 block8_sepconv2\n",
            "71 block8_sepconv2_bn\n",
            "72 block8_sepconv3_act\n",
            "73 block8_sepconv3\n",
            "74 block8_sepconv3_bn\n",
            "75 add_6\n",
            "76 block9_sepconv1_act\n",
            "77 block9_sepconv1\n",
            "78 block9_sepconv1_bn\n",
            "79 block9_sepconv2_act\n",
            "80 block9_sepconv2\n",
            "81 block9_sepconv2_bn\n",
            "82 block9_sepconv3_act\n",
            "83 block9_sepconv3\n",
            "84 block9_sepconv3_bn\n",
            "85 add_7\n",
            "86 block10_sepconv1_act\n",
            "87 block10_sepconv1\n",
            "88 block10_sepconv1_bn\n",
            "89 block10_sepconv2_act\n",
            "90 block10_sepconv2\n",
            "91 block10_sepconv2_bn\n",
            "92 block10_sepconv3_act\n",
            "93 block10_sepconv3\n",
            "94 block10_sepconv3_bn\n",
            "95 add_8\n",
            "96 block11_sepconv1_act\n",
            "97 block11_sepconv1\n",
            "98 block11_sepconv1_bn\n",
            "99 block11_sepconv2_act\n",
            "100 block11_sepconv2\n",
            "101 block11_sepconv2_bn\n",
            "102 block11_sepconv3_act\n",
            "103 block11_sepconv3\n",
            "104 block11_sepconv3_bn\n",
            "105 add_9\n",
            "106 block12_sepconv1_act\n",
            "107 block12_sepconv1\n",
            "108 block12_sepconv1_bn\n",
            "109 block12_sepconv2_act\n",
            "110 block12_sepconv2\n",
            "111 block12_sepconv2_bn\n",
            "112 block12_sepconv3_act\n",
            "113 block12_sepconv3\n",
            "114 block12_sepconv3_bn\n",
            "115 add_10\n",
            "116 block13_sepconv1_act\n",
            "117 block13_sepconv1\n",
            "118 block13_sepconv1_bn\n",
            "119 block13_sepconv2_act\n",
            "120 block13_sepconv2\n",
            "121 block13_sepconv2_bn\n",
            "122 conv2d_3\n",
            "123 block13_pool\n",
            "124 batch_normalization_4\n",
            "125 add_11\n",
            "126 block14_sepconv1\n",
            "127 block14_sepconv1_bn\n",
            "128 block14_sepconv1_act\n",
            "129 block14_sepconv2\n",
            "130 block14_sepconv2_bn\n",
            "131 block14_sepconv2_act\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuAWX1NF1pSw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3c274456-c02f-4f42-e78c-bef26bb24154"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "img_input = keras.layers.Input(shape=(224, 224, 3)) # defining the Input shape\n",
        "Encoder_Inception = InceptionV3( weights = 'imagenet',include_top =False,input_tensor=img_input)\n",
        "model=Encoder_Inception\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 111, 111, 32) 864         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 111, 111, 32) 96          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 111, 111, 32) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 109, 109, 32) 9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 109, 109, 32) 96          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 109, 109, 32) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 109, 109, 64) 18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 109, 109, 64) 192         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 109, 109, 64) 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 54, 54, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 54, 54, 80)   240         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 54, 54, 80)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 52, 52, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 52, 52, 192)  576         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 52, 52, 192)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 25, 25, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 25, 25, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 25, 25, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 25, 25, 48)   144         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 25, 25, 96)   288         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 25, 25, 48)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 25, 25, 96)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 25, 25, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 25, 25, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 25, 25, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 25, 25, 64)   192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 25, 25, 64)   192         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 25, 25, 96)   288         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 25, 25, 32)   96          conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 25, 25, 64)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 25, 25, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 25, 25, 32)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 25, 25, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 25, 25, 48)   144         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 25, 25, 96)   288         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 25, 25, 48)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 25, 25, 96)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 25, 25, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 25, 25, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 25, 25, 64)   192         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 25, 25, 96)   288         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 25, 25, 64)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 25, 25, 64)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 25, 25, 64)   192         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 25, 25, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 25, 25, 48)   144         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 25, 25, 96)   288         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 25, 25, 48)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 25, 25, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 25, 25, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 25, 25, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 25, 25, 64)   192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 25, 25, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 25, 25, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 25, 25, 64)   192         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 25, 25, 64)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 25, 25, 64)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 25, 25, 64)   192         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 25, 25, 64)   0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 25, 25, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 25, 25, 96)   288         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 25, 25, 96)   0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 12, 12, 96)   82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 12, 12, 384)  1152        conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 12, 12, 96)   288         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 12, 12, 384)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 12, 12, 96)   0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 12, 12, 128)  384         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 128)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 12, 12, 128)  114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 12, 12, 128)  384         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 12, 12, 128)  384         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 12, 12, 128)  384         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 12, 12, 192)  172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 12, 12, 192)  172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 12, 12, 192)  576         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 12, 12, 192)  576         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 12, 12, 192)  576         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 12, 12, 192)  576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 192)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 192)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 192)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 12, 12, 160)  480         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 12, 12, 160)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 12, 12, 160)  179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 12, 12, 160)  480         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 12, 12, 160)  480         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 12, 12, 192)  215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 12, 12, 192)  215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 12, 12, 192)  576         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 12, 12, 192)  576         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 12, 12, 192)  576         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 12, 12, 192)  576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 12, 12, 192)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 12, 12, 192)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 12, 12, 160)  480         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 12, 12, 160)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 12, 12, 160)  179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 12, 12, 160)  480         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 12, 12, 160)  480         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 12, 12, 160)  480         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 12, 12, 192)  215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 12, 12, 192)  215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 12, 12, 192)  576         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 12, 12, 192)  576         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 12, 12, 192)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 12, 12, 192)  258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 12, 12, 192)  576         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 12, 12, 192)  576         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 12, 12, 192)  0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 12, 12, 192)  258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 12, 12, 192)  576         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 12, 12, 192)  576         conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 5, 5, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 5, 5, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 5, 5, 320)    960         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 5, 5, 192)    576         conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 5, 5, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 5, 5, 192)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 5, 5, 448)    1344        conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 5, 5, 448)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 5, 5, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 5, 5, 384)    1152        conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 5, 5, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 5, 5, 320)    960         conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 5, 5, 192)    576         conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 5, 5, 320)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 5, 5, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 5, 5, 192)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 5, 5, 448)    1344        conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 5, 5, 448)    0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 5, 5, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 5, 5, 384)    1152        conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 5, 5, 384)    0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 5, 5, 384)    1152        conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 5, 5, 384)    1152        conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 5, 5, 320)    960         conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 5, 5, 192)    576         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 5, 5, 320)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 5, 5, 192)    0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoaQzDSf2YTx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "daf863d4-40fd-4308-e367-d5de7cf5dafe"
      },
      "source": [
        "for i, layer in enumerate(model.layers):\n",
        "   print(i, layer.name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_3\n",
            "1 conv2d_4\n",
            "2 batch_normalization_5\n",
            "3 activation\n",
            "4 conv2d_5\n",
            "5 batch_normalization_6\n",
            "6 activation_1\n",
            "7 conv2d_6\n",
            "8 batch_normalization_7\n",
            "9 activation_2\n",
            "10 max_pooling2d\n",
            "11 conv2d_7\n",
            "12 batch_normalization_8\n",
            "13 activation_3\n",
            "14 conv2d_8\n",
            "15 batch_normalization_9\n",
            "16 activation_4\n",
            "17 max_pooling2d_1\n",
            "18 conv2d_12\n",
            "19 batch_normalization_13\n",
            "20 activation_8\n",
            "21 conv2d_10\n",
            "22 conv2d_13\n",
            "23 batch_normalization_11\n",
            "24 batch_normalization_14\n",
            "25 activation_6\n",
            "26 activation_9\n",
            "27 average_pooling2d\n",
            "28 conv2d_9\n",
            "29 conv2d_11\n",
            "30 conv2d_14\n",
            "31 conv2d_15\n",
            "32 batch_normalization_10\n",
            "33 batch_normalization_12\n",
            "34 batch_normalization_15\n",
            "35 batch_normalization_16\n",
            "36 activation_5\n",
            "37 activation_7\n",
            "38 activation_10\n",
            "39 activation_11\n",
            "40 mixed0\n",
            "41 conv2d_19\n",
            "42 batch_normalization_20\n",
            "43 activation_15\n",
            "44 conv2d_17\n",
            "45 conv2d_20\n",
            "46 batch_normalization_18\n",
            "47 batch_normalization_21\n",
            "48 activation_13\n",
            "49 activation_16\n",
            "50 average_pooling2d_1\n",
            "51 conv2d_16\n",
            "52 conv2d_18\n",
            "53 conv2d_21\n",
            "54 conv2d_22\n",
            "55 batch_normalization_17\n",
            "56 batch_normalization_19\n",
            "57 batch_normalization_22\n",
            "58 batch_normalization_23\n",
            "59 activation_12\n",
            "60 activation_14\n",
            "61 activation_17\n",
            "62 activation_18\n",
            "63 mixed1\n",
            "64 conv2d_26\n",
            "65 batch_normalization_27\n",
            "66 activation_22\n",
            "67 conv2d_24\n",
            "68 conv2d_27\n",
            "69 batch_normalization_25\n",
            "70 batch_normalization_28\n",
            "71 activation_20\n",
            "72 activation_23\n",
            "73 average_pooling2d_2\n",
            "74 conv2d_23\n",
            "75 conv2d_25\n",
            "76 conv2d_28\n",
            "77 conv2d_29\n",
            "78 batch_normalization_24\n",
            "79 batch_normalization_26\n",
            "80 batch_normalization_29\n",
            "81 batch_normalization_30\n",
            "82 activation_19\n",
            "83 activation_21\n",
            "84 activation_24\n",
            "85 activation_25\n",
            "86 mixed2\n",
            "87 conv2d_31\n",
            "88 batch_normalization_32\n",
            "89 activation_27\n",
            "90 conv2d_32\n",
            "91 batch_normalization_33\n",
            "92 activation_28\n",
            "93 conv2d_30\n",
            "94 conv2d_33\n",
            "95 batch_normalization_31\n",
            "96 batch_normalization_34\n",
            "97 activation_26\n",
            "98 activation_29\n",
            "99 max_pooling2d_2\n",
            "100 mixed3\n",
            "101 conv2d_38\n",
            "102 batch_normalization_39\n",
            "103 activation_34\n",
            "104 conv2d_39\n",
            "105 batch_normalization_40\n",
            "106 activation_35\n",
            "107 conv2d_35\n",
            "108 conv2d_40\n",
            "109 batch_normalization_36\n",
            "110 batch_normalization_41\n",
            "111 activation_31\n",
            "112 activation_36\n",
            "113 conv2d_36\n",
            "114 conv2d_41\n",
            "115 batch_normalization_37\n",
            "116 batch_normalization_42\n",
            "117 activation_32\n",
            "118 activation_37\n",
            "119 average_pooling2d_3\n",
            "120 conv2d_34\n",
            "121 conv2d_37\n",
            "122 conv2d_42\n",
            "123 conv2d_43\n",
            "124 batch_normalization_35\n",
            "125 batch_normalization_38\n",
            "126 batch_normalization_43\n",
            "127 batch_normalization_44\n",
            "128 activation_30\n",
            "129 activation_33\n",
            "130 activation_38\n",
            "131 activation_39\n",
            "132 mixed4\n",
            "133 conv2d_48\n",
            "134 batch_normalization_49\n",
            "135 activation_44\n",
            "136 conv2d_49\n",
            "137 batch_normalization_50\n",
            "138 activation_45\n",
            "139 conv2d_45\n",
            "140 conv2d_50\n",
            "141 batch_normalization_46\n",
            "142 batch_normalization_51\n",
            "143 activation_41\n",
            "144 activation_46\n",
            "145 conv2d_46\n",
            "146 conv2d_51\n",
            "147 batch_normalization_47\n",
            "148 batch_normalization_52\n",
            "149 activation_42\n",
            "150 activation_47\n",
            "151 average_pooling2d_4\n",
            "152 conv2d_44\n",
            "153 conv2d_47\n",
            "154 conv2d_52\n",
            "155 conv2d_53\n",
            "156 batch_normalization_45\n",
            "157 batch_normalization_48\n",
            "158 batch_normalization_53\n",
            "159 batch_normalization_54\n",
            "160 activation_40\n",
            "161 activation_43\n",
            "162 activation_48\n",
            "163 activation_49\n",
            "164 mixed5\n",
            "165 conv2d_58\n",
            "166 batch_normalization_59\n",
            "167 activation_54\n",
            "168 conv2d_59\n",
            "169 batch_normalization_60\n",
            "170 activation_55\n",
            "171 conv2d_55\n",
            "172 conv2d_60\n",
            "173 batch_normalization_56\n",
            "174 batch_normalization_61\n",
            "175 activation_51\n",
            "176 activation_56\n",
            "177 conv2d_56\n",
            "178 conv2d_61\n",
            "179 batch_normalization_57\n",
            "180 batch_normalization_62\n",
            "181 activation_52\n",
            "182 activation_57\n",
            "183 average_pooling2d_5\n",
            "184 conv2d_54\n",
            "185 conv2d_57\n",
            "186 conv2d_62\n",
            "187 conv2d_63\n",
            "188 batch_normalization_55\n",
            "189 batch_normalization_58\n",
            "190 batch_normalization_63\n",
            "191 batch_normalization_64\n",
            "192 activation_50\n",
            "193 activation_53\n",
            "194 activation_58\n",
            "195 activation_59\n",
            "196 mixed6\n",
            "197 conv2d_68\n",
            "198 batch_normalization_69\n",
            "199 activation_64\n",
            "200 conv2d_69\n",
            "201 batch_normalization_70\n",
            "202 activation_65\n",
            "203 conv2d_65\n",
            "204 conv2d_70\n",
            "205 batch_normalization_66\n",
            "206 batch_normalization_71\n",
            "207 activation_61\n",
            "208 activation_66\n",
            "209 conv2d_66\n",
            "210 conv2d_71\n",
            "211 batch_normalization_67\n",
            "212 batch_normalization_72\n",
            "213 activation_62\n",
            "214 activation_67\n",
            "215 average_pooling2d_6\n",
            "216 conv2d_64\n",
            "217 conv2d_67\n",
            "218 conv2d_72\n",
            "219 conv2d_73\n",
            "220 batch_normalization_65\n",
            "221 batch_normalization_68\n",
            "222 batch_normalization_73\n",
            "223 batch_normalization_74\n",
            "224 activation_60\n",
            "225 activation_63\n",
            "226 activation_68\n",
            "227 activation_69\n",
            "228 mixed7\n",
            "229 conv2d_76\n",
            "230 batch_normalization_77\n",
            "231 activation_72\n",
            "232 conv2d_77\n",
            "233 batch_normalization_78\n",
            "234 activation_73\n",
            "235 conv2d_74\n",
            "236 conv2d_78\n",
            "237 batch_normalization_75\n",
            "238 batch_normalization_79\n",
            "239 activation_70\n",
            "240 activation_74\n",
            "241 conv2d_75\n",
            "242 conv2d_79\n",
            "243 batch_normalization_76\n",
            "244 batch_normalization_80\n",
            "245 activation_71\n",
            "246 activation_75\n",
            "247 max_pooling2d_3\n",
            "248 mixed8\n",
            "249 conv2d_84\n",
            "250 batch_normalization_85\n",
            "251 activation_80\n",
            "252 conv2d_81\n",
            "253 conv2d_85\n",
            "254 batch_normalization_82\n",
            "255 batch_normalization_86\n",
            "256 activation_77\n",
            "257 activation_81\n",
            "258 conv2d_82\n",
            "259 conv2d_83\n",
            "260 conv2d_86\n",
            "261 conv2d_87\n",
            "262 average_pooling2d_7\n",
            "263 conv2d_80\n",
            "264 batch_normalization_83\n",
            "265 batch_normalization_84\n",
            "266 batch_normalization_87\n",
            "267 batch_normalization_88\n",
            "268 conv2d_88\n",
            "269 batch_normalization_81\n",
            "270 activation_78\n",
            "271 activation_79\n",
            "272 activation_82\n",
            "273 activation_83\n",
            "274 batch_normalization_89\n",
            "275 activation_76\n",
            "276 mixed9_0\n",
            "277 concatenate\n",
            "278 activation_84\n",
            "279 mixed9\n",
            "280 conv2d_93\n",
            "281 batch_normalization_94\n",
            "282 activation_89\n",
            "283 conv2d_90\n",
            "284 conv2d_94\n",
            "285 batch_normalization_91\n",
            "286 batch_normalization_95\n",
            "287 activation_86\n",
            "288 activation_90\n",
            "289 conv2d_91\n",
            "290 conv2d_92\n",
            "291 conv2d_95\n",
            "292 conv2d_96\n",
            "293 average_pooling2d_8\n",
            "294 conv2d_89\n",
            "295 batch_normalization_92\n",
            "296 batch_normalization_93\n",
            "297 batch_normalization_96\n",
            "298 batch_normalization_97\n",
            "299 conv2d_97\n",
            "300 batch_normalization_90\n",
            "301 activation_87\n",
            "302 activation_88\n",
            "303 activation_91\n",
            "304 activation_92\n",
            "305 batch_normalization_98\n",
            "306 activation_85\n",
            "307 mixed9_1\n",
            "308 concatenate_1\n",
            "309 activation_93\n",
            "310 mixed10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHOBb_nr1pVr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1dca7571-43ab-4091-f538-6221bab819c9"
      },
      "source": [
        "Encoder = keras.layers.SeparableConv2D(filters = 1024,kernel_size = (3, 3),activation = 'relu',kernel_initializer='he_normal',padding=\"same\")(Encoder_Inception.output)\n",
        "Encoder = keras.layers.BatchNormalization()(Encoder)\n",
        "print(Encoder.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 5, 5, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvOZNZa31pY5"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql8ow7R40Fe1"
      },
      "source": [
        "# residual block may can apply with any number of layers.\n",
        "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
        "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    if activation == True:\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "    return x\n",
        "\n",
        "def residual_block(blockInput, num_filters=16):\n",
        "    x = LeakyReLU(alpha=0.1)(blockInput)\n",
        "    x = BatchNormalization()(x)\n",
        "    blockInput = BatchNormalization()(blockInput)\n",
        "    x = convolution_block(x, num_filters, (3,3) )\n",
        "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
        "    x = Add()([x, blockInput])\n",
        "    return x\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE0sqksW0HCV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "9832ab77-1b1d-4873-f895-ce36d4792c51"
      },
      "source": [
        "import os\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from keras.layers import MaxPooling2D, UpSampling2D, Convolution2D, Input, merge, concatenate\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "from skimage.io import imsave\n",
        "import keras\n",
        "from keras import optimizers\n",
        "##from data import load_train_data, load_test_data\n",
        "#\n",
        "K.set_image_data_format('channels_last')  # TF dimension ordering in this code\n",
        "#\n",
        "#img_rows = 128\n",
        "#img_cols = 128\n",
        "#\n",
        "smooth = 1.\n",
        "epochs = 200\n",
        "optimizerada=optimizers.Adadelta(1.0, rho=0.95)\n",
        "##optimizernadam=optimizers.Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999)\n",
        "##optimizeradamx=optimizers.Adamax(learning_rate=0.002, beta_1=0.9, beta_2=0.999)\n",
        "#ptimizeradamxRMS=optimizers.RMSprop(lr=0.001, rho=0.9)\n",
        "\n",
        "def merge(inputs, mode, concat_axis=-1):\n",
        "    return concatenate(inputs, concat_axis)\n",
        "\n",
        "RMSpropoa=optimizers.RMSprop(lr=0.001,rho=0.9)\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)\n",
        "\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    \"\"\"Precision metric.\n",
        "\n",
        "    Only computes a batch-wise average of precision.\n",
        "\n",
        "    Computes the precision, a metric for multi-label classification of\n",
        "    how many selected items are relevant.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    \"\"\"Recall metric.\n",
        "\n",
        "    Only computes a batch-wise average of recall.\n",
        "\n",
        "    Computes the recall, a metric for multi-label classification of\n",
        "    how many relevant items are selected.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def f1score(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2 * ((precision * recall) / (precision + recall))\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-white')\n",
        "import seaborn as sns\n",
        "sns.set_style(\"white\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from skimage.transform import resize\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from keras.losses import binary_crossentropy\n",
        "\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras import Model\n",
        "from keras.callbacks import  ModelCheckpoint\n",
        "from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout,BatchNormalization\n",
        "from keras.layers import Conv2D, Concatenate, MaxPooling2D\n",
        "from keras.layers import UpSampling2D, Dropout, BatchNormalization\n",
        "from tqdm import tqdm_notebook\n",
        "from keras import initializers\n",
        "from keras import regularizers\n",
        "from keras import constraints\n",
        "from keras.utils import conv_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.engine.topology import get_source_inputs\n",
        "from keras.engine import InputSpec\n",
        "from keras import backend as K\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import ZeroPadding2D\n",
        "from keras.losses import binary_crossentropy\n",
        "import keras.callbacks as callbacks\n",
        "from keras.callbacks import Callback\n",
        "from keras.applications.xception import Xception\n",
        "from keras.layers import multiply\n",
        "\n",
        "\n",
        "from keras import optimizers\n",
        "from keras.legacy import interfaces\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "\n",
        "from keras.engine.topology import Input\n",
        "from keras.engine.training import Model\n",
        "from keras.layers.convolutional import Conv2D, UpSampling2D, Conv2DTranspose\n",
        "from keras.layers.core import Activation, SpatialDropout2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
        "from keras.regularizers import l2\n",
        "from keras.layers.core import Dense, Lambda\n",
        "from keras.layers.merge import concatenate, add\n",
        "from keras.layers import GlobalAveragePooling2D, Reshape, Dense, multiply, Permute\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
        "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    if activation == True:\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "    return x\n",
        "\n",
        "def residual_block(blockInput, num_filters=16):\n",
        "    x = LeakyReLU(alpha=0.1)(blockInput)\n",
        "    x = BatchNormalization()(x)\n",
        "    blockInput = BatchNormalization()(blockInput)\n",
        "    x = convolution_block(x, num_filters, (3,3) )\n",
        "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
        "    x = Add()([x, blockInput])\n",
        "    return x\n",
        "\n",
        "def attention_up_and_concate1(down_layer, layer):\n",
        "    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n",
        "    up = UpSampling2D(size=(2, 2))(down_layer)\n",
        "\n",
        "    layer = attention_block_2d1(x=layer, g=up, inter_channel=in_channel // 4)\n",
        "    my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
        "    concate = my_concat([up, layer])\n",
        "    return concate\n",
        "\n",
        "\n",
        "def attention_block_2d1(x, g, inter_channel):\n",
        "    # theta_x(?,g_height,g_width,inter_channel)\n",
        "\n",
        "    theta_x = Conv2D(inter_channel, [1, 1], strides=[1, 1])(x)\n",
        "\n",
        "    # phi_g(?,g_height,g_width,inter_channel)\n",
        "\n",
        "    phi_g = Conv2D(inter_channel, [1, 1], strides=[1, 1])(g)\n",
        "\n",
        "    # f(?,g_height,g_width,inter_channel)\n",
        "\n",
        "    f = Activation('relu')(add([theta_x, phi_g]))\n",
        "\n",
        "    # psi_f(?,g_height,g_width,1)\n",
        "\n",
        "    psi_f = Conv2D(1, [1, 1], strides=[1, 1])(f)\n",
        "\n",
        "    rate = Activation('sigmoid')(psi_f)\n",
        "\n",
        "    # rate(?,x_height,x_width)\n",
        "\n",
        "    # att_x(?,x_height,x_width,x_channel)\n",
        "\n",
        "    att_x = multiply([x, rate])\n",
        "\n",
        "    return att_x\n",
        "\n",
        "in_channel=1024\n",
        "\n",
        "def UXception(input_shape=(None, None, 3)):\n",
        "\n",
        "    backbone = Xception(input_shape=input_shape,weights='imagenet',include_top=False)\n",
        "    input = backbone.input\n",
        "    start_neurons = 16\n",
        "\n",
        "    conv4 = backbone.layers[121].output\n",
        "    conv4 = LeakyReLU(alpha=0.1)(conv4)\n",
        "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
        "    pool4 = Dropout(0.1)(pool4)\n",
        "\n",
        "     # Middle\n",
        "    convm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4)\n",
        "    convm = residual_block(convm,start_neurons * 32)\n",
        "    convm = residual_block(convm,start_neurons * 32)\n",
        "    convm = LeakyReLU(alpha=0.1)(convm)\n",
        "\n",
        "    # 10 -> 20\n",
        "    #deconv4 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
        "    #uconv4 = concatenate([deconv4, conv4])\n",
        "    uconv4=attention_up_and_concate1(convm, conv4)\n",
        "    uconv4 = Dropout(0.1)(uconv4)\n",
        "\n",
        "    uconv4 = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
        "    uconv4 = residual_block(uconv4,start_neurons * 16)\n",
        "    uconv4 = residual_block(uconv4,start_neurons * 16)\n",
        "    uconv4 = LeakyReLU(alpha=0.1)(uconv4)\n",
        "\n",
        "    # 10 -> 20\n",
        "    #deconv3 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
        "    conv3 = backbone.layers[31].output\n",
        "    #uconv3 = concatenate([deconv3, conv3])\n",
        "    uconv3=attention_up_and_concate1(uconv4, conv3)\n",
        "    uconv3 = Dropout(0.1)(uconv3)\n",
        "\n",
        "    uconv3 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
        "    uconv3 = residual_block(uconv3,start_neurons * 8)\n",
        "    uconv3 = residual_block(uconv3,start_neurons * 8)\n",
        "    uconv3 = LeakyReLU(alpha=0.1)(uconv3)\n",
        "\n",
        "    # 20 -> 40\n",
        "    #deconv2 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
        "    conv2 = backbone.layers[21].output\n",
        "    conv2 = ZeroPadding2D(((1,0),(1,0)))(conv2)\n",
        "    uconv2=attention_up_and_concate1(uconv3, conv2)\n",
        "    #uconv2 = concatenate([deconv2, conv2])\n",
        "\n",
        "    uconv2 = Dropout(0.1)(uconv2)\n",
        "    uconv2 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
        "    uconv2 = residual_block(uconv2,start_neurons * 4)\n",
        "    uconv2 = residual_block(uconv2,start_neurons * 4)\n",
        "    uconv2 = LeakyReLU(alpha=0.1)(uconv2)\n",
        "\n",
        "    # 40 -> 80\n",
        "    #deconv1 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
        "    conv1 = backbone.layers[11].output\n",
        "    conv1 = ZeroPadding2D(((3,0),(3,0)))(conv1)\n",
        "    #uconv1 = concatenate([deconv1, conv1])\n",
        "    uconv1=attention_up_and_concate1(uconv2, conv1)\n",
        "\n",
        "    uconv1 = Dropout(0.1)(uconv1)\n",
        "    uconv1 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
        "    uconv1 = residual_block(uconv1,start_neurons * 2)\n",
        "    uconv1 = residual_block(uconv1,start_neurons * 2)\n",
        "    uconv1 = LeakyReLU(alpha=0.1)(uconv1)\n",
        "\n",
        "\n",
        "    # 80 -> 160\n",
        "    uconv0 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv1)\n",
        "    uconv0 = Dropout(0.1)(uconv0)\n",
        "    uconv0 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv0)\n",
        "    uconv0 = residual_block(uconv0,start_neurons * 1)\n",
        "    uconv0 = residual_block(uconv0,start_neurons * 1)\n",
        "    uconv0 = LeakyReLU(alpha=0.1)(uconv0)\n",
        "\n",
        "    uconv0 = Dropout(0.1/2)(uconv0)\n",
        "    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv0)\n",
        "\n",
        "    model = Model(input, output_layer)\n",
        "    model.name = 'u-xception'\n",
        "\n",
        "    return model\n",
        "\n",
        "img_size_target=128\n",
        "model = UXception(input_shape=(img_size_target,img_size_target,3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zZmUndniWpL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9f43810-e6b5-47f3-aec7-0c26160c90b6"
      },
      "source": [
        "img_size_target=128\n",
        "input_shape=(img_size_target,img_size_target,3)\n",
        "backbone = Xception(input_shape=input_shape,weights='imagenet',include_top=False)\n",
        "input = backbone.input\n",
        "start_neurons = 16\n",
        "conv4 = backbone.layers[121].output\n",
        "conv4 = LeakyReLU(alpha=0.1)(conv4)\n",
        "pool4 = MaxPooling2D((2, 2))(conv4)\n",
        "pool4 = Dropout(0.1)(pool4)\n",
        "print(pool4.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 4, 4, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vo6Nb1ki4cB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "1b42ed07-8d55-4e20-e52c-65cabc22ed9c"
      },
      "source": [
        "# 10 -> 20\n",
        "#deconv4 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
        "#uconv4 = concatenate([deconv4, conv4])\n",
        "uconv4=attention_up_and_concate1(convm, conv4)\n",
        "print(conv4.shape)\n",
        "print(convm.shape)\n",
        "uconv4 = Dropout(0.1)(uconv4)\n",
        "print(uconv4.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-52b9dfa2186c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#deconv4 = Conv2DTranspose(start_neurons * 16, (3, 3), strides=(2, 2), padding=\"same\")(convm)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#uconv4 = concatenate([deconv4, conv4])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0muconv4\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_up_and_concate1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'convm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMJrqRvjjUSs"
      },
      "source": [
        "uconv4 = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
        "uconv4 = residual_block(uconv4,start_neurons * 16)\n",
        "uconv4 = residual_block(uconv4,start_neurons * 16)\n",
        "uconv4 = LeakyReLU(alpha=0.1)(uconv4)\n",
        "print(uconv4.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-PcmfSLjfa-"
      },
      "source": [
        "#deconv3 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
        "conv3 = backbone.layers[31].output\n",
        "print(conv3.shape)\n",
        "print(uconv4.shape)\n",
        "#uconv3 = concatenate([deconv3, conv3])\n",
        "uconv3=attention_up_and_concate1(uconv4, conv3)\n",
        "uconv3 = Dropout(0.1)(uconv3)\n",
        "print(uconv3.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff8LznvZisEz"
      },
      "source": [
        " # Middle\n",
        "convm = Conv2D(start_neurons * 32, (3, 3), activation=None, padding=\"same\")(pool4)\n",
        "print(convm.shape)\n",
        "convm = residual_block(convm,start_neurons * 32)\n",
        "convm = residual_block(convm,start_neurons * 32)\n",
        "convm = LeakyReLU(alpha=0.1)(convm)\n",
        "print(convm.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyWaGuEsm0n5"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIipbG_Um0rg"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rjZYdOfm0uY"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqy4WIH1m0xM"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM2Ope2mm00J"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwLgjO92m03O"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WUkbSfK0HFN"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJhuTC-p0HH8"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqrNeCdJ0HKr"
      },
      "source": [
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import *\n",
        "from keras.losses import *\n",
        "from keras import backend as keras\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.applications.densenet import DenseNet201, DenseNet121\n",
        "from keras.utils import plot_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "#------------------------------Others python Packages---------------------------\n",
        "import numpy as np # High-level mathematical functions for n-dimensional arrays\n",
        "import os\n",
        "import cv2\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import numpy as np\n",
        "import glob\n",
        "from PIL import Image\n",
        "import skimage\n",
        "from keras.initializers import Constant\n",
        "from matplotlib import pyplot as plt\n",
        "#%matplotlib inline\n",
        "from skimage.morphology import disk\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from skimage.measure import label, regionprops\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import jaccard_similarity_score\n",
        "\n",
        "###################3Designing of Proposed DSNet#######################################\n",
        "def DSNet(nClasses, input_height, input_width):\n",
        "\n",
        "    #------------------------------Define Input Shape----------------------------------\n",
        "\n",
        "    img_input = Input(shape=(input_height, input_width, 3)) # defining the Input shape\n",
        "\n",
        "    #Load DenseNet121 from keras. This model is initialized with the ImageNet.\n",
        "    #This part is responsible for the feature extraction which is so called convolution\n",
        "    # part of the semantic segmentation (Encoder).\n",
        "\n",
        "    Encoder_Dense = DenseNet121( weights = 'imagenet',\n",
        "\t\t\t\t\t\tinclude_top = False,\n",
        "\t\t\t\t\t\tinput_tensor = img_input)\n",
        "\n",
        "    Encoder = SeparableConv2D(filters = 1024,\n",
        "\t\t\t\t\tkernel_size = (3, 3),\n",
        "\t\t\t\t\tactivation = 'relu',\n",
        "\t\t\t\t\tkernel_initializer='he_normal',\n",
        "\t\t\t\t\tpadding=\"same\")(Encoder_Dense.output)\n",
        "    Encoder = BatchNormalization()(Encoder)\n",
        "\n",
        "\n",
        "    # Decoding the encoded features to reconstruct the original input shape Image.\n",
        "\n",
        "    Decoder = UpSampling2D(size = (2, 2))(Encoder)\n",
        "    Decoder = concatenate([Encoder_Dense.get_layer(name=\"pool3_pool\").output, Decoder], axis=-1)\n",
        "    Decoder = SeparableConv2D(filters = 1024,\n",
        "\t\t\t\t\t\tkernel_size = (3, 3),\n",
        "\t\t\t\t\t\tactivation = 'relu',\n",
        "\t\t\t\t\t\tkernel_initializer='he_normal',\n",
        "\t\t\t\t\t\tpadding = \"same\")(Decoder)\n",
        "    Decoder = BatchNormalization()(Decoder)\n",
        "    Decoder = UpSampling2D(size = (2, 2))(Decoder)\n",
        "    Decoder = concatenate([Encoder_Dense.get_layer(name=\"pool2_pool\").output, Decoder], axis=-1)\n",
        "    Decoder = SeparableConv2D(filters = 512,\n",
        "\t\t\t\t\t\tkernel_size = (3, 3),\n",
        "\t\t\t\t\t\tactivation = 'relu',\n",
        "\t\t\t\t\t\tkernel_initializer='he_normal',\n",
        "\t\t\t\t\t\tpadding = \"same\")(Decoder)\n",
        "    Decoder = BatchNormalization()(Decoder)\n",
        "\n",
        "    Decoder = UpSampling2D(size = (2, 2))(Decoder)\n",
        "    Decoder = concatenate([Encoder_Dense.get_layer(name=\"pool1\").output, Decoder], axis=-1)\n",
        "    Decoder = SeparableConv2D(filters = 256,\n",
        "\t\t\t\t\t\tkernel_size = (3, 3),\n",
        "\t\t\t\t\t\tactivation = 'relu',\n",
        "\t\t\t\t\t\tkernel_initializer='he_normal',\n",
        "\t\t\t\t\t\tpadding = \"same\")(Decoder)\n",
        "    Decoder = BatchNormalization()(Decoder)\n",
        "\n",
        "    Decoder = UpSampling2D( size = (2, 2))(Decoder)\n",
        "    Decoder = concatenate([Encoder_Dense.get_layer(name=\"conv1/bn\").output, Decoder], axis=-1)\n",
        "    Decoder = SeparableConv2D(filters = 128,\n",
        "\t\t\t\t\t\tkernel_size = (3, 3),\n",
        "\t\t\t\t\t\tactivation = 'relu',\n",
        "\t\t\t\t\t\tkernel_initializer='he_normal',\n",
        "\t\t\t\t\t\tpadding = \"same\")(Decoder)\n",
        "    Decoder = BatchNormalization()(Decoder)\n",
        "\n",
        "    Decoder = UpSampling2D(size = (2, 2))(Decoder)\n",
        "    Decoder = SeparableConv2D(filters = 64,\n",
        "\t\t\t\t\t\tkernel_size = (3, 3),\n",
        "\t\t\t\t\t\tactivation = 'relu',\n",
        "\t\t\t\t\t\tkernel_initializer='he_normal',\n",
        "\t\t\t\t\t\tpadding = \"same\")(Decoder)\n",
        "    Decoder = BatchNormalization()(Decoder)\n",
        "\n",
        "    Decoder = SeparableConv2D(filters = nClasses,\n",
        "\t\t\t\t\t\tkernel_size = (1, 1),\n",
        "\t\t\t\t\t\tactivation = 'relu',\n",
        "\t\t\t\t\t\tkernel_initializer='he_normal',\n",
        "\t\t\t\t\t\tpadding = \"same\")(Decoder)\n",
        "    Decoder = BatchNormalization()(Decoder)\n",
        "\n",
        "\n",
        "    Predicted_Mask = Conv2D(filters = 1,\n",
        "\t\t\t\t\t\t\t\t\tkernel_size = 1,\n",
        "\t\t\t\t\t\t\t\t\tactivation = 'sigmoid')(Decoder)\n",
        "\n",
        "\n",
        "    DSNet_model = Model(input = img_input, output = Predicted_Mask)\n",
        "\n",
        "    return DSNet_model\n",
        "\n",
        "model=DSNet(1, 256, 256)\n",
        "#model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLMS8Vjij4E0"
      },
      "source": [
        "input_height=256\n",
        "input_width=256\n",
        "img_input = Input(shape=(input_height, input_width, 3)) # defining the Input shape\n",
        "#Load DenseNet121 from keras. This model is initialized with the ImageNet.\n",
        "#This part is responsible for the feature extraction which is so called convolution\n",
        "# part of the semantic segmentation (Encoder).\n",
        "Encoder_Dense = DenseNet121( weights = 'imagenet',include_top = False,input_tensor = img_input)\n",
        "Encoder = SeparableConv2D(filters = 1024,kernel_size = (3, 3),activation = 'relu',kernel_initializer='he_normal',padding=\"same\")(Encoder_Dense.output)\n",
        "Encoder = BatchNormalization()(Encoder)\n",
        "print(Encoder.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9FawELskc__"
      },
      "source": [
        "# Decoding the encoded features to reconstruct the original input shape Image.\n",
        "Decoder = UpSampling2D(size = (2, 2))(Encoder)\n",
        "print(Decoder.shape)\n",
        "print(Encoder_Dense.get_layer(name=\"pool3_pool\").output.shape)\n",
        "Decoder = concatenate([Encoder_Dense.get_layer(name=\"pool3_pool\").output, Decoder], axis=-1)\n",
        "print(Decoder.shape)\n",
        "Decoder = SeparableConv2D(filters = 1024,kernel_size = (3, 3),activation = 'relu',kernel_initializer='he_normal',padding = \"same\")(Decoder)\n",
        "Decoder = BatchNormalization()(Decoder)\n",
        "print(Decoder.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1kWJga-lIs9"
      },
      "source": [
        "Decoder = UpSampling2D(size = (2, 2))(Decoder)\n",
        "print(Decoder.shape)\n",
        "print(Encoder_Dense.get_layer(name=\"pool2_pool\").output.shape)\n",
        "Decoder = concatenate([Encoder_Dense.get_layer(name=\"pool2_pool\").output, Decoder], axis=-1)\n",
        "print(Decoder.shape)\n",
        "Decoder = SeparableConv2D(filters = 512,kernel_size = (3, 3),activation = 'relu',kernel_initializer='he_normal',padding = \"same\")(Decoder)\n",
        "Decoder = BatchNormalization()(Decoder)\n",
        "print(Decoder.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77UgPAz9ldJD"
      },
      "source": [
        "Decoder = UpSampling2D(size = (2, 2))(Decoder)\n",
        "print(Decoder.shape)\n",
        "print(Encoder_Dense.get_layer(name=\"pool1\").output.shape)\n",
        "Decoder = concatenate([Encoder_Dense.get_layer(name=\"pool1\").output, Decoder], axis=-1)\n",
        "print(Decoder.shape)\n",
        "Decoder = SeparableConv2D(filters = 256,kernel_size = (3, 3),activation = 'relu',kernel_initializer='he_normal',padding = \"same\")(Decoder)\n",
        "Decoder = BatchNormalization()(Decoder)\n",
        "print(Decoder.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te3HVK_9lx9l"
      },
      "source": [
        "Decoder = UpSampling2D( size = (2, 2))(Decoder)\n",
        "print(Decoder.shape)\n",
        "print(Encoder_Dense.get_layer(name=\"conv1/bn\").output.shape)\n",
        "Decoder = concatenate([Encoder_Dense.get_layer(name=\"conv1/bn\").output, Decoder], axis=-1)\n",
        "print(Decoder.shape)\n",
        "Decoder = SeparableConv2D(filters = 128,kernel_size = (3, 3),activation = 'relu',kernel_initializer='he_normal',padding = \"same\")(Decoder)\n",
        "Decoder = BatchNormalization()(Decoder)\n",
        "print(Decoder.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLxC4sySmFPV"
      },
      "source": [
        "Decoder = UpSampling2D(size = (2, 2))(Decoder)\n",
        "print(Decoder.shape)\n",
        "Decoder = SeparableConv2D(filters = 64,kernel_size = (3, 3),activation = 'relu',kernel_initializer='he_normal',padding = \"same\")(Decoder)\n",
        "Decoder = BatchNormalization()(Decoder)\n",
        "print(Decoder.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZCFEICamVRL"
      },
      "source": [
        "nClasses=3\n",
        "Decoder = SeparableConv2D(filters = nClasses,kernel_size = (1, 1),activation = 'relu',kernel_initializer='he_normal',padding = \"same\")(Decoder)\n",
        "Decoder = BatchNormalization()(Decoder)\n",
        "print(Decoder.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYHe-mWFmkxV"
      },
      "source": [
        "Predicted_Mask = Conv2D(filters = 1,kernel_size = 1,activation = 'sigmoid')(Decoder)\n",
        "print(Predicted_Mask.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqi5G6_p0HNj"
      },
      "source": [
        "# Inception-ResNetV2 segmentation model\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from datetime import datetime\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "\n",
        "import imgaug\n",
        "from imgaug import augmenters as iaa\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (Input, BatchNormalization, Conv2D, MaxPooling2D,                             \t\t\t\t\t\tAveragePooling2D, ZeroPadding2D, concatenate,\n",
        "\t\t\t\t\tConcatenate, UpSampling2D, Activation, Lambda)\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard\n",
        "from tensorflow.keras import metrics\n",
        "\n",
        "\n",
        "# Inception model\n",
        "bn_axis = 3\n",
        "channel_axis = bn_axis\n",
        "def conv_block(prev, num_filters, kernel=(3, 3), strides=(1, 1), act='relu', prefix=None):\n",
        "    name = None\n",
        "    if prefix is not None:\n",
        "        name = prefix + '_conv'\n",
        "    conv = Conv2D(num_filters, kernel, padding='same', kernel_initializer='he_normal', strides=strides, name=name)(prev)\n",
        "    if prefix is not None:\n",
        "        name = prefix + '_norm'\n",
        "    conv = BatchNormalization(name=name, axis=bn_axis)(conv)\n",
        "    if prefix is not None:\n",
        "        name = prefix + '_act'\n",
        "    conv = Activation(act, name=name)(conv)\n",
        "    return conv\n",
        "\n",
        "def conv2d_bn(x,\n",
        "              filters,\n",
        "              kernel_size,\n",
        "              strides=1,\n",
        "              padding='same',\n",
        "              activation='relu',\n",
        "              use_bias=False,\n",
        "              name=None):\n",
        "    \"\"\"Utility function to apply conv + BN.\n",
        "    # Arguments\n",
        "        x: input tensor.\n",
        "        filters: filters in `Conv2D`.\n",
        "        kernel_size: kernel size as in `Conv2D`.\n",
        "        strides: strides in `Conv2D`.\n",
        "        padding: padding mode in `Conv2D`.\n",
        "        activation: activation in `Conv2D`.\n",
        "        use_bias: whether to use a bias in `Conv2D`.\n",
        "        name: name of the ops; will become `name + '_ac'` for the activation\n",
        "            and `name + '_bn'` for the batch norm layer.\n",
        "    # Returns\n",
        "        Output tensor after applying `Conv2D` and `BatchNormalization`.\n",
        "    \"\"\"\n",
        "    x = Conv2D(filters,\n",
        "              kernel_size,\n",
        "              strides=strides,\n",
        "              padding=padding,\n",
        "              use_bias=use_bias,\n",
        "              name=name)(x)\n",
        "    if not use_bias:\n",
        "            bn_axis = 3\n",
        "            bn_name = None if name is None else name + '_bn'\n",
        "            x = BatchNormalization(axis=bn_axis,\n",
        "                                          scale=False,\n",
        "                                          name=bn_name)(x)\n",
        "    if activation is not None:\n",
        "        ac_name = None if name is None else name + '_ac'\n",
        "        x = Activation(activation, name=ac_name)(x)\n",
        "    return x\n",
        "\n",
        "def inception_resnet_block(x, scale, block_type, block_idx, activation='relu'):\n",
        "    \"\"\"Adds a Inception-ResNet block.\n",
        "    This function builds 3 types of Inception-ResNet blocks mentioned\n",
        "    in the paper, controlled by the `block_type` argument (which is the\n",
        "    block name used in the official TF-slim implementation):\n",
        "        - Inception-ResNet-A: `block_type='block35'`\n",
        "        - Inception-ResNet-B: `block_type='block17'`\n",
        "        - Inception-ResNet-C: `block_type='block8'`\n",
        "    # Arguments\n",
        "        x: input tensor.\n",
        "        scale: scaling factor to scale the residuals (i.e., the output of\n",
        "            passing `x` through an inception module) before adding them\n",
        "            to the shortcut branch.\n",
        "            Let `r` be the output from the residual branch,\n",
        "            the output of this block will be `x + scale * r`.\n",
        "        block_type: `'block35'`, `'block17'` or `'block8'`, determines\n",
        "            the network structure in the residual branch.\n",
        "        block_idx: an `int` used for generating layer names.\n",
        "            The Inception-ResNet blocks\n",
        "            are repeated many times in this network.\n",
        "            We use `block_idx` to identify\n",
        "            each of the repetitions. For example,\n",
        "            the first Inception-ResNet-A block\n",
        "            will have `block_type='block35', block_idx=0`,\n",
        "            and the layer names will have\n",
        "            a common prefix `'block35_0'`.\n",
        "        activation: activation function to use at the end of the block\n",
        "            (see [activations](../activations.md)).\n",
        "            When `activation=None`, no activation is applied\n",
        "            (i.e., \"linear\" activation: `a(x) = x`).\n",
        "    # Returns\n",
        "        Output tensor for the block.\n",
        "    # Raises\n",
        "        ValueError: if `block_type` is not one of `'block35'`,\n",
        "            `'block17'` or `'block8'`.\n",
        "    \"\"\"\n",
        "    if block_type == 'block35':\n",
        "        branch_0 = conv2d_bn(x, 32, 1)\n",
        "        branch_1 = conv2d_bn(x, 32, 1)\n",
        "        branch_1 = conv2d_bn(branch_1, 32, 3)\n",
        "        branch_2 = conv2d_bn(x, 32, 1)\n",
        "        branch_2 = conv2d_bn(branch_2, 48, 3)\n",
        "        branch_2 = conv2d_bn(branch_2, 64, 3)\n",
        "        branches = [branch_0, branch_1, branch_2]\n",
        "    elif block_type == 'block17':\n",
        "        branch_0 = conv2d_bn(x, 192, 1)\n",
        "        branch_1 = conv2d_bn(x, 128, 1)\n",
        "        branch_1 = conv2d_bn(branch_1, 160, [1, 7])\n",
        "        branch_1 = conv2d_bn(branch_1, 192, [7, 1])\n",
        "        branches = [branch_0, branch_1]\n",
        "    elif block_type == 'block8':\n",
        "        branch_0 = conv2d_bn(x, 192, 1)\n",
        "        branch_1 = conv2d_bn(x, 192, 1)\n",
        "        branch_1 = conv2d_bn(branch_1, 224, [1, 3])\n",
        "        branch_1 = conv2d_bn(branch_1, 256, [3, 1])\n",
        "        branches = [branch_0, branch_1]\n",
        "    else:\n",
        "        raise ValueError('Unknown Inception-ResNet block type. '\n",
        "                         'Expects \"block35\", \"block17\" or \"block8\", '\n",
        "                         'but got: ' + str(block_type))\n",
        "\n",
        "    block_name = block_type + '_' + str(block_idx)\n",
        "    channel_axis = 3\n",
        "    mixed = Concatenate(\n",
        "        axis=channel_axis, name=block_name + '_mixed')(branches)\n",
        "    up = conv2d_bn(mixed,\n",
        "                   K.int_shape(x)[channel_axis],\n",
        "                   1,\n",
        "                   activation=None,\n",
        "                   use_bias=True,\n",
        "                   name=block_name + '_conv')\n",
        "\n",
        "    x = Lambda(lambda inputs, scale: inputs[0] + inputs[1] * scale,\n",
        "                      output_shape=K.int_shape(x)[1:],\n",
        "                      arguments={'scale': scale},\n",
        "                      name=block_name)([x, up])\n",
        "    if activation is not None:\n",
        "        x = Activation(activation, name=block_name + '_ac')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_inception_resnet_v2_unet_softmax(input_shape, weights='imagenet'):\n",
        "    n_channel = 3\n",
        "    n_class = 4\n",
        "    img_input = Input(input_shape + (n_channel,))\n",
        "\n",
        "    # Stem block: 35 x 35 x 192\n",
        "    x = conv2d_bn(img_input, 32, 3, strides=2, padding='same')\n",
        "    x = conv2d_bn(x, 32, 3, padding='same')\n",
        "    x = conv2d_bn(x, 64, 3)\n",
        "    conv1 = x\n",
        "    x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
        "    x = conv2d_bn(x, 80, 1, padding='same')\n",
        "    x = conv2d_bn(x, 192, 3, padding='same')\n",
        "    conv2 = x\n",
        "    x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
        "\n",
        "    # Mixed 5b (Inception-A block): 35 x 35 x 320\n",
        "    branch_0 = conv2d_bn(x, 96, 1)\n",
        "    branch_1 = conv2d_bn(x, 48, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 64, 5)\n",
        "    branch_2 = conv2d_bn(x, 64, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 96, 3)\n",
        "    branch_2 = conv2d_bn(branch_2, 96, 3)\n",
        "    branch_pool = AveragePooling2D(3, strides=1, padding='same')(x)\n",
        "    branch_pool = conv2d_bn(branch_pool, 64, 1)\n",
        "    branches = [branch_0, branch_1, branch_2, branch_pool]\n",
        "    channel_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
        "    x = Concatenate(axis=channel_axis, name='mixed_5b')(branches)\n",
        "\n",
        "    # 10x block35 (Inception-ResNet-A block): 35 x 35 x 320\n",
        "    for block_idx in range(1, 11):\n",
        "        x = inception_resnet_block(x,\n",
        "                                   scale=0.17,\n",
        "                                   block_type='block35',\n",
        "                                   block_idx=block_idx)\n",
        "    conv3 = x\n",
        "    # Mixed 6a (Reduction-A block): 17 x 17 x 1088\n",
        "    branch_0 = conv2d_bn(x, 384, 3, strides=2, padding='same')\n",
        "    branch_1 = conv2d_bn(x, 256, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 256, 3)\n",
        "    branch_1 = conv2d_bn(branch_1, 384, 3, strides=2, padding='same')\n",
        "    branch_pool = MaxPooling2D(3, strides=2, padding='same')(x)\n",
        "    branches = [branch_0, branch_1, branch_pool]\n",
        "    x = Concatenate(axis=channel_axis, name='mixed_6a')(branches)\n",
        "\n",
        "    # 20x block17 (Inception-ResNet-B block): 17 x 17 x 1088\n",
        "    for block_idx in range(1, 21):\n",
        "        x = inception_resnet_block(x,\n",
        "                                   scale=0.1,\n",
        "                                   block_type='block17',\n",
        "                                   block_idx=block_idx)\n",
        "    conv4 = x\n",
        "    # Mixed 7a (Reduction-B block): 8 x 8 x 2080\n",
        "    branch_0 = conv2d_bn(x, 256, 1)\n",
        "    branch_0 = conv2d_bn(branch_0, 384, 3, strides=2, padding='same')\n",
        "    branch_1 = conv2d_bn(x, 256, 1)\n",
        "    branch_1 = conv2d_bn(branch_1, 288, 3, strides=2, padding='same')\n",
        "    branch_2 = conv2d_bn(x, 256, 1)\n",
        "    branch_2 = conv2d_bn(branch_2, 288, 3)\n",
        "    branch_2 = conv2d_bn(branch_2, 320, 3, strides=2, padding='same')\n",
        "    branch_pool = MaxPooling2D(3, strides=2, padding='same')(x)\n",
        "    branches = [branch_0, branch_1, branch_2, branch_pool]\n",
        "    x = Concatenate(axis=channel_axis, name='mixed_7a')(branches)\n",
        "\n",
        "    # 10x block8 (Inception-ResNet-C block): 8 x 8 x 2080\n",
        "    for block_idx in range(1, 10):\n",
        "        x = inception_resnet_block(x,\n",
        "                                   scale=0.2,\n",
        "                                   block_type='block8',\n",
        "                                   block_idx=block_idx)\n",
        "    x = inception_resnet_block(x,\n",
        "                               scale=1.,\n",
        "                               activation=None,\n",
        "                               block_type='block8',\n",
        "                               block_idx=10)\n",
        "\n",
        "    # Final convolution block: 8 x 8 x 1536\n",
        "    x = conv2d_bn(x, 1536, 1, name='conv_7b')\n",
        "    conv5 = x\n",
        "\n",
        "    conv6 = conv_block(UpSampling2D()(conv5), 320)\n",
        "    conv6 = concatenate([conv6, conv4], axis=-1)\n",
        "    conv6 = conv_block(conv6, 320)\n",
        "\n",
        "    conv7 = conv_block(UpSampling2D()(conv6), 256)\n",
        "    conv7 = concatenate([conv7, conv3], axis=-1)\n",
        "    conv7 = conv_block(conv7, 256)\n",
        "\n",
        "    conv8 = conv_block(UpSampling2D()(conv7), 128)\n",
        "    conv8 = concatenate([conv8, conv2], axis=-1)\n",
        "    conv8 = conv_block(conv8, 128)\n",
        "\n",
        "    conv9 = conv_block(UpSampling2D()(conv8), 96)\n",
        "    conv9 = concatenate([conv9, conv1], axis=-1)\n",
        "    conv9 = conv_block(conv9, 96)\n",
        "\n",
        "    conv10 = conv_block(UpSampling2D()(conv9), 64)\n",
        "    conv10 = conv_block(conv10, 64)\n",
        "    res = Conv2D(n_class, (1, 1), activation='softmax')(conv10)\n",
        "\n",
        "    model = Model(img_input, res)\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMSaSgOq0HQM"
      },
      "source": [
        "n_class=4\n",
        "model = get_inception_resnet_v2_unet_softmax(input_shape=(256,256), weights=None)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfWFFeOx5gP5"
      },
      "source": [
        "# example of creating a CNN with an efficient inception module\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.utils import plot_model\n",
        "\n",
        "# function for creating a projected inception module\n",
        "def inception_module(layer_in, f1, f2_in, f2_out, f3_in, f3_out, f4_out):\n",
        "\t# 1x1 conv\n",
        "\tconv1 = Conv2D(f1, (1,1), padding='same', activation='relu')(layer_in)\n",
        "\t# 3x3 conv\n",
        "\tconv3 = Conv2D(f2_in, (1,1), padding='same', activation='relu')(layer_in)\n",
        "\tconv3 = Conv2D(f2_out, (3,3), padding='same', activation='relu')(conv3)\n",
        "\t# 5x5 conv\n",
        "\tconv5 = Conv2D(f3_in, (1,1), padding='same', activation='relu')(layer_in)\n",
        "\tconv5 = Conv2D(f3_out, (5,5), padding='same', activation='relu')(conv5)\n",
        "\t# 3x3 max pooling\n",
        "\tpool = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_in)\n",
        "\tpool = Conv2D(f4_out, (1,1), padding='same', activation='relu')(pool)\n",
        "\t# concatenate filters, assumes filters/channels last\n",
        "\tlayer_out = concatenate([conv1, conv3, conv5, pool], axis=-1)\n",
        "\treturn layer_out\n",
        "\n",
        "# define model input\n",
        "visible = Input(shape=(256, 256, 3))\n",
        "# add inception block 1\n",
        "layer = inception_module(visible, 64, 96, 128, 16, 32, 32)\n",
        "# add inception block 1\n",
        "layer = inception_module(layer, 128, 128, 192, 32, 96, 64)\n",
        "# create model\n",
        "model = Model(inputs=visible, outputs=layer)\n",
        "# summarize model\n",
        "model.summary()\n",
        "# plot model architecture\n",
        "plot_model(model, show_shapes=True, to_file='inception_module.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUvelFGK6J9g"
      },
      "source": [
        "# inception module in keras\n",
        "import keras\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, SeparableConv2D\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import SGD, RMSprop\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.layers import Input, GlobalAveragePooling2D\n",
        "from keras import models\n",
        "from keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIbT6Rxx6PMQ"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "input_img = keras.layers.Input(shape=(224, 224, 1))\n",
        "\n",
        "### 1st layer\n",
        "layer_1 = keras.layers.Conv2D(10, (1,1), padding='same', activation='relu')(input_img)\n",
        "layer_1 = keras.layers.Conv2D(10, (3,3), padding='same', activation='relu')(layer_1)\n",
        "print(layer_1.shape)\n",
        "layer_2 = keras.layers.Conv2D(10, (1,1), padding='same', activation='relu')(input_img)\n",
        "layer_2 = keras.layers.Conv2D(10, (5,5), padding='same', activation='relu')(layer_2)\n",
        "print(layer_2.shape)\n",
        "layer_3 = keras.layers.MaxPooling2D((3,3), strides=(1,1), padding='same')(input_img)\n",
        "layer_3 = keras.layers.Conv2D(10, (1,1), padding='same', activation='relu')(layer_3)\n",
        "print(layer_3.shape)\n",
        "mid_1 = keras.layers.concatenate([layer_1, layer_2, layer_3], axis = 3)\n",
        "print(mid_1.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkYP1RhF6RyJ"
      },
      "source": [
        "def inception_module(x,\n",
        "                     filters_1x1,\n",
        "                     filters_3x3_reduce,\n",
        "                     filters_3x3,\n",
        "                     filters_5x5_reduce,\n",
        "                     filters_5x5,\n",
        "                     filters_pool_proj,\n",
        "                     name=None):\n",
        "\n",
        "    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
        "\n",
        "    conv_3x3 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
        "    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_3x3)\n",
        "\n",
        "    conv_5x5 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
        "    conv_5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_5x5)\n",
        "\n",
        "    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(pool_proj)\n",
        "\n",
        "    output = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3, name=name)\n",
        "\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRvguo4M6auF"
      },
      "source": [
        "kernel_init = keras.initializers.glorot_uniform()\n",
        "bias_init = keras.initializers.Constant(value=0.2)\n",
        "input_layer = Input(shape=(224, 224, 3))\n",
        "\n",
        "x = Conv2D(64, (7, 7), padding='same', strides=(2, 2), activation='relu', name='conv_1_7x7/2', kernel_initializer=kernel_init, bias_initializer=bias_init)(input_layer)\n",
        "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_1_3x3/2')(x)\n",
        "x = Conv2D(64, (1, 1), padding='same', strides=(1, 1), activation='relu', name='conv_2a_3x3/1')(x)\n",
        "x = Conv2D(192, (3, 3), padding='same', strides=(1, 1), activation='relu', name='conv_2b_3x3/1')(x)\n",
        "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_2_3x3/2')(x)\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=64,\n",
        "                     filters_3x3_reduce=96,\n",
        "                     filters_3x3=128,\n",
        "                     filters_5x5_reduce=16,\n",
        "                     filters_5x5=32,\n",
        "                     filters_pool_proj=32,\n",
        "                     name='inception_3a')\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=128,\n",
        "                     filters_3x3_reduce=128,\n",
        "                     filters_3x3=192,\n",
        "                     filters_5x5_reduce=32,\n",
        "                     filters_5x5=96,\n",
        "                     filters_pool_proj=64,\n",
        "                     name='inception_3b')\n",
        "\n",
        "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_3_3x3/2')(x)\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=192,\n",
        "                     filters_3x3_reduce=96,\n",
        "                     filters_3x3=208,\n",
        "                     filters_5x5_reduce=16,\n",
        "                     filters_5x5=48,\n",
        "                     filters_pool_proj=64,\n",
        "                     name='inception_4a')\n",
        "\n",
        "\n",
        "x1 = AveragePooling2D((5, 5), strides=3)(x)\n",
        "x1 = Conv2D(128, (1, 1), padding='same', activation='relu')(x1)\n",
        "x1 = Flatten()(x1)\n",
        "x1 = Dense(1024, activation='relu')(x1)\n",
        "x1 = Dropout(0.7)(x1)\n",
        "x1 = Dense(10, activation='softmax', name='auxilliary_output_1')(x1)\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=160,\n",
        "                     filters_3x3_reduce=112,\n",
        "                     filters_3x3=224,\n",
        "                     filters_5x5_reduce=24,\n",
        "                     filters_5x5=64,\n",
        "                     filters_pool_proj=64,\n",
        "                     name='inception_4b')\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=128,\n",
        "                     filters_3x3_reduce=128,\n",
        "                     filters_3x3=256,\n",
        "                     filters_5x5_reduce=24,\n",
        "                     filters_5x5=64,\n",
        "                     filters_pool_proj=64,\n",
        "                     name='inception_4c')\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=112,\n",
        "                     filters_3x3_reduce=144,\n",
        "                     filters_3x3=288,\n",
        "                     filters_5x5_reduce=32,\n",
        "                     filters_5x5=64,\n",
        "                     filters_pool_proj=64,\n",
        "                     name='inception_4d')\n",
        "\n",
        "\n",
        "x2 = AveragePooling2D((5, 5), strides=3)(x)\n",
        "x2 = Conv2D(128, (1, 1), padding='same', activation='relu')(x2)\n",
        "x2 = Flatten()(x2)\n",
        "x2 = Dense(1024, activation='relu')(x2)\n",
        "x2 = Dropout(0.7)(x2)\n",
        "x2 = Dense(10, activation='softmax', name='auxilliary_output_2')(x2)\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=256,\n",
        "                     filters_3x3_reduce=160,\n",
        "                     filters_3x3=320,\n",
        "                     filters_5x5_reduce=32,\n",
        "                     filters_5x5=128,\n",
        "                     filters_pool_proj=128,\n",
        "                     name='inception_4e')\n",
        "\n",
        "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_4_3x3/2')(x)\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=256,\n",
        "                     filters_3x3_reduce=160,\n",
        "                     filters_3x3=320,\n",
        "                     filters_5x5_reduce=32,\n",
        "                     filters_5x5=128,\n",
        "                     filters_pool_proj=128,\n",
        "                     name='inception_5a')\n",
        "\n",
        "x = inception_module(x,\n",
        "                     filters_1x1=384,\n",
        "                     filters_3x3_reduce=192,\n",
        "                     filters_3x3=384,\n",
        "                     filters_5x5_reduce=48,\n",
        "                     filters_5x5=128,\n",
        "                     filters_pool_proj=128,\n",
        "                     name='inception_5b')\n",
        "\n",
        "x = GlobalAveragePooling2D(name='avg_pool_5_3x3/1')(x)\n",
        "\n",
        "x = Dropout(0.4)(x)\n",
        "\n",
        "x = Dense(10, activation='softmax', name='output')(x)\n",
        "\n",
        "model = Model(input_layer, [x, x1, x2], name='inception_v1')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}